<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Fast convolutions (I) | Brash &amp; Plucky</title>
<meta name="generator" content="Jekyll v4.3.2" />
<meta property="og:title" content="Fast convolutions (I)" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="In my previous post it was stated that the convolution of a WxH image with a wxh kernel is a new WxH image where each pixel is the sum of wxh products obtained as the central pixel of the kernel slides across each of the pixels in the original image. This double-double loop leads to an impractical O(n^4) algorithm complexity." />
<meta property="og:description" content="In my previous post it was stated that the convolution of a WxH image with a wxh kernel is a new WxH image where each pixel is the sum of wxh products obtained as the central pixel of the kernel slides across each of the pixels in the original image. This double-double loop leads to an impractical O(n^4) algorithm complexity." />
<link rel="canonical" href="http://localhost:4000/2014/07/18/fast-convolutions-i.html" />
<meta property="og:url" content="http://localhost:4000/2014/07/18/fast-convolutions-i.html" />
<meta property="og:site_name" content="Brash &amp; Plucky" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2014-07-18T03:55:00+02:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Fast convolutions (I)" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2014-07-18T03:55:00+02:00","datePublished":"2014-07-18T03:55:00+02:00","description":"In my previous post it was stated that the convolution of a WxH image with a wxh kernel is a new WxH image where each pixel is the sum of wxh products obtained as the central pixel of the kernel slides across each of the pixels in the original image. This double-double loop leads to an impractical O(n^4) algorithm complexity.","headline":"Fast convolutions (I)","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/2014/07/18/fast-convolutions-i.html"},"url":"http://localhost:4000/2014/07/18/fast-convolutions-i.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" title="Brash &amp; Plucky" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Brash &amp; Plucky</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Fast convolutions (I)</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2014-07-18T03:55:00+02:00" itemprop="datePublished">Jul 18, 2014
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>In my <a href="https://www.brashandplucky.com/pointspread-functions-convolutions.html">previous post</a> it was stated that the convolution of a <code class="language-plaintext highlighter-rouge">WxH</code> image with a <code class="language-plaintext highlighter-rouge">wxh</code> kernel is a new <code class="language-plaintext highlighter-rouge">WxH</code> image where each pixel is the sum of <code class="language-plaintext highlighter-rouge">wxh</code> products obtained as the central pixel of the kernel slides across each of the pixels in the original image. This double-double loop leads to an impractical <code class="language-plaintext highlighter-rouge">O(n^4)</code> algorithm complexity.</p>

<p>Fortunately, we can do better, but the key here is not in optimizing the code, but in making use of some mathematical weaponry. Let’s analyze the options that we have:</p>

<ol>
  <li>Naive implementation.</li>
  <li>Separable convolution kernels.</li>
  <li>The convolution theorem.</li>
  <li>Can we do EVEN better?</li>
</ol>

<h3 id="naive-implementation">Naive implementation</h3>

<p><em>Pros:</em></p>

<ul>
  <li>Trivial implementation in just a few lines of code.</li>
  <li>Works for any input size, and for any type of kernel.</li>
  <li>Trivial clamping at the boundaries.</li>
  <li>Allows for multi-threading.</li>
</ul>

<p><em>Cons:</em></p>

<ul>
  <li>Embarrassingly inefficient: <code class="language-plaintext highlighter-rouge">O(n^4)</code>.</li>
  <li>Requires an auxiliary <code class="language-plaintext highlighter-rouge">WxH</code> buffer.</li>
  <li>By default, the output of the operation is returned in the auxiliary buffer (not <em>in-place</em>).</li>
  <li>Not very cache friendly due to the constant jumps across rows.
– Applying the same kernel multiple times has the same cost, every time.</li>
</ul>

<p><em>When should I use this method?</em></p>

<ul>
  <li>Never, unless the input data is tiny and clean code is more important than sheer performance.</li>
</ul>

<h3 id="separable-convolution-kernels">Separable convolution kernels</h3>

<p>A separable convolution kernel is one that can be broken into two 1D (vertical and horizontal) projections. For these projections the (matrix) product of the <code class="language-plaintext highlighter-rouge">1xh</code> vertical kernel by the <code class="language-plaintext highlighter-rouge">wx1</code> horizontal kernel must restore the original <code class="language-plaintext highlighter-rouge">wxh</code> 2D kernel.</p>

<p><em>1D vertical and horizontal Gaussian convolution</em></p>

<p><img src="/uploads/2022/4171094912.png" width="600" height="402" alt="" /></p>

<p>Conveniently enough, the most usual convolution kernels (<em>e.g.,</em> Gaussian blur, box blur, …) happen to be separable.</p>

<p>The convolution of an image by a separable convolution kernel becomes the following:</p>

<ol>
  <li>Convolute the rows of the original image with the horizontal kernel projection.</li>
  <li>Convolute the columns of the resulting image with the vertical kernel projection.</li>
</ol>

<p>Note: These two steps are commutative.</p>

<p><em>2-step separable vs. brute-force 2D Gaussian convolution</em></p>

<p><img src="/uploads/2022/35a6c714ba.png" width="600" height="608" alt="" /></p>

<p><em>Pros:</em></p>

<ul>
  <li>More efficient than the naive implementation: <code class="language-plaintext highlighter-rouge">O(n^3)</code>.</li>
  <li>Trivial implementation in just a few lines of code.</li>
  <li>Trivial clamping at the boundaries.</li>
  <li>Works for any input size.</li>
  <li>Since this is a two-step process, the convolution can be returned <em>in-place</em>.</li>
  <li>Cache-friendly.</li>
  <li>Allows for multi-threading.</li>
</ul>

<p><em>Cons:</em></p>

<ul>
  <li>Only works with separable kernels.</li>
  <li>Needs an auxiliary <code class="language-plaintext highlighter-rouge">WxH</code> buffer.</li>
  <li>Applying the same kernel multiple times has the same cost, every time.</li>
</ul>

<p><em>When should I use this method?</em></p>

<ul>
  <li>We do not use this method anywhere in Maverick’s API. You will understand why soon.</li>
</ul>

<h3 id="the-convolution-theorem">The convolution theorem</h3>

<p>“The <a href="https://en.wikipedia.org/wiki/Convolution_theorem">convolution</a> in the spatial domain is equivalent to a point-wise product in the frequency domain, and vice-versa.”</p>

<p>This method relies on the (Fast) <a href="https://en.wikipedia.org/wiki/Fourier_transform">Fourier Transform</a>, which is one of the most beautiful mathematical constructs, ever. Seriously!</p>

<p>The convolution of an image by a generic kernel becomes the following:</p>

<ol>
  <li>Compute the Fourier Transform of the image.</li>
  <li>Compute the Fourier Transform of the kernel.</li>
  <li>Multiply both Fourier Transforms, point-wise.</li>
  <li>Compute the Inverse Fourier Transform of the result.</li>
</ol>

<p><em>Brute-force 2D Gaussian vs. the convolution theorem</em></p>

<p><img src="/uploads/2022/71f4742163.png" width="600" height="609" alt="" /></p>

<p><em>Magic</em></p>

<p><img src="/uploads/2022/9fd4b3d82e.gif" width="350" height="196" alt="" /></p>

<p><em>Pros:</em></p>

<ul>
  <li>Even more efficient: <code class="language-plaintext highlighter-rouge">O(n^2·log(n))</code>.</li>
  <li>Works with any convolution kernel, separable or not.</li>
  <li>Should the kernel be applied multiple times, the FFT of the kernel can be computed just once, and then be re-used.</li>
  <li>The FFT/IFFT and the convolution product are cache-friendly.</li>
  <li>The FFT/IFFT and the convolution product allow for multi-threading.</li>
</ul>

<p><em>Cons:</em></p>

<ul>
  <li>Definitely not easy to implement, unless you already own an FFT module that suits your needs.</li>
  <li>The FFT operates on buffers with power-of-2 dimensions. This means that the input image (and the kernel) must be padded with zeroes to a larger size (<em>i.e.,</em> extra setup time + memory).</li>
  <li>Both the image and the kernel are transformed, which requires two auxiliary buffers instead of one.</li>
  <li>Each FFT produces complex-number values, which doubles the memory usage of each auxiliary buffer.</li>
  <li>The dynamic range of the FFT values is generally wilder than that of the original image. This requires a careful implementation, and the use of floating-point math regardless of the bit-depth and range of the input image.</li>
  <li>This method doesn’t do any clamping at the boundaries of the image, producing a very annoying warp-around effect that may need special handling (<em>e.g.,</em> more padding).</li>
</ul>

<p><em>When should I use this method?</em></p>

<ul>
  <li>Every time that a large generic convolution kernel (<em>i.e.,</em> not a simple blur) is involved.</li>
  <li>The most obvious examples I can think of in Maverick’s are Glare &amp; Bloom.</li>
</ul>

<h3 id="can-we-do-even-better">Can we do EVEN better?</h3>

<p>Oh yes. We can do much better, at least in the very particular case of blur. I will talk about this in detail in a dedicated blog entry, at some point.</p>

<p><strong>Some implementation remarks:</strong></p>

<p>All the algorithms presented above allow for <strong>multi-threading</strong>. Naturally, MT does not change the algorithm complexity, since the maximum number of threads is fixed, but you can get very decent speeds in practical cases if you combine sleek code with proper multi-threading. In the separable case (2), MT must be used twice. First for the rows, and then for the cols. In the FFT case (3), the FFT itself can be multi-threaded (in a rows/cols fashion as well). The huge point-wise product in frequency space can be MT’ed too.</p>

<p>Since convolutions are usually applied on very large images, writing <strong>cache-friendly code</strong> can make a big difference. Assuming that the memory layout of your image/kernel is per rows, make sure to arrange your loops so memory accesses are as consecutive as possible. This is immediate for the loops that do a 1D convolution on each row. However, for the loops that do a 1D convolution on each column, it may help to use a local cache to transpose a column to a row back and forth.</p>

  </div><a class="u-url" href="/2014/07/18/fast-convolutions-i.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Brash &amp; Plucky</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Brash &amp; Plucky</li><li><a class="u-email" href="mailto:brashandplucky@gmail.com">brashandplucky@gmail.com</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/chemaguerra"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">chemaguerra</span></a></li><li><a href="https://www.twitter.com/chemaguerra"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">chemaguerra</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description.</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
