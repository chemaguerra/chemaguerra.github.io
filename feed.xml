<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2023-07-14T17:56:15+02:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Chema Guerra</title><subtitle>Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description.</subtitle><entry><title type="html">Truncated SVD</title><link href="http://localhost:4000/math/2d/coding/2023/07/05/truncated-svd.html" rel="alternate" type="text/html" title="Truncated SVD" /><published>2023-07-05T22:52:40+02:00</published><updated>2023-07-05T22:52:40+02:00</updated><id>http://localhost:4000/math/2d/coding/2023/07/05/truncated-svd</id><content type="html" xml:base="http://localhost:4000/math/2d/coding/2023/07/05/truncated-svd.html">&lt;p&gt;NOTE: This write-up is not finished yet…&lt;/p&gt;

&lt;h3 id=&quot;pca&quot;&gt;PCA&lt;/h3&gt;

&lt;p&gt;https://en.wikipedia.org/wiki/Principal_component_analysis&lt;/p&gt;

&lt;p&gt;This is accomplished by linearly transforming the data into a new coordinate system where (most of) the variation in the data can be described with fewer dimensions than the initial data.&lt;/p&gt;

&lt;p&gt;Without getting into the details, this is done via an eigen-decomposition of the &lt;a href=&quot;https://en.wikipedia.org/wiki/Covariance_matrix&quot;&gt;covariance matrix&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/uploads/2023/pca.gif&quot; width=&quot;600&quot; height=&quot;240&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;svd&quot;&gt;SVD&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Singular Value Decomposition&lt;/em&gt; (&lt;a href=&quot;https://en.wikipedia.org/wiki/Singular_value_decomposition&quot;&gt;SVD&lt;/a&gt;) is a matrix factorization technique that factors a real matrix &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;M&lt;/code&gt; into three matrices &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;U&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Σ&lt;/code&gt;, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;V&lt;/code&gt; such that &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;M=U*Σ*V_T&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;If &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;M&lt;/code&gt; is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mxn&lt;/code&gt;, then &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;U&lt;/code&gt; is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mxm&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Σ&lt;/code&gt; is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;mxn&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;V&lt;/code&gt; is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nxn&lt;/code&gt;. Both &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;U&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;V&lt;/code&gt; are orthonormal, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Σ&lt;/code&gt; is rectangular-diagonal with non-negative coefficients.&lt;/p&gt;

&lt;p&gt;This is very similar to PCA, excepting that the factorization for SVD is done on the data matrix, whereas for PCA, the factorization is done on the covariance matrix.&lt;/p&gt;

&lt;p&gt;The diagonal coefficients of S are known as the &lt;em&gt;singular values&lt;/em&gt; of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;M&lt;/code&gt; and it is common practice to rearrange the SVD so the singular values are given in decreasing order. The number of non-zero singular values is equal to the rank of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;M&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The SVD is tightly &lt;a href=&quot;https://intoli.com/blog/pca-and-svd/&quot;&gt;related to PCA&lt;/a&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The columns of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;V&lt;/code&gt; are principal directions/axes (eigenvectors).&lt;/li&gt;
  &lt;li&gt;Columns of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;U*Σ&lt;/code&gt; are principal components (scores).&lt;/li&gt;
  &lt;li&gt;Singular values are related to the eigenvalues of the covariance matrix.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;From Wikipedia:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/uploads/2023/chemaguerra-svd-matrices.png&quot; width=&quot;440&quot; height=&quot;513&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;truncated-svd&quot;&gt;Truncated SVD&lt;/h3&gt;

&lt;p&gt;Let’s try with a 1024x1024 grayscale image of the moon:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/uploads/2023/chemaguerra-moon.png&quot; width=&quot;600&quot; height=&quot;600&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Such an image can be interpreted as 1024 vectors of 1024 components each. &lt;em&gt;i.e.,&lt;/em&gt; a set of 1024 vectors in a 1024-dimension space.&lt;/p&gt;

&lt;p&gt;If we run PCA/SVD on this set, the three matrices &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;U&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Σ&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;V&lt;/code&gt; will be 1024x1024. In particular, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Σ&lt;/code&gt; will be a square-diagonal matrix. &lt;em&gt;i.e.,&lt;/em&gt; only the coefficients in the diagonal are potentially non-zero. It is common practice to rearrange the three matrices so the diagonal indices in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Σ&lt;/code&gt; are sorted from greater (top-left) to lower (bottom-right).&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Truncated SVD&lt;/em&gt; is simply the act of zeroing-out all the coefficients in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Σ&lt;/code&gt; except for the top-left &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;n&lt;/code&gt; ones.&lt;/p&gt;

&lt;p&gt;Coefficient truncation implies that we’re also trashing &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;1024-n&lt;/code&gt; columns in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;U&lt;/code&gt; and in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;V&lt;/code&gt; (as now those will be multiplied by 0 anyway).&lt;/p&gt;

&lt;p&gt;If we now reconstruct the original matrix &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;M&apos;=U&apos;*Σ&apos;*V_T&apos;&lt;/code&gt; using the truncated matrices, we will obtain &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;M&apos;&lt;/code&gt;, which will resemble &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;M&lt;/code&gt;. The fewer the coefficients that we drop, the more closely that &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;M&apos;&lt;/code&gt; will approximate &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;M&lt;/code&gt;. But because of the information-preserving properties of PCA/SVD, keeping just a bunch of the topmost coefficients in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Σ&lt;/code&gt; may suffice to restore all (or near all) the original information.&lt;/p&gt;

&lt;h4 id=&quot;here-goes-a-demo&quot;&gt;Here goes a demo&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;The left half is the reconstructed matrix &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;M&apos;&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;The right half is the reconstruction error &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;abs(M-M&apos;)&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;The decreasing yellow graph is the MSE as fewer and fewer singular values are zeroed-out.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/uploads/2023/chemaguerra-moon-svd.jpg&quot; width=&quot;600&quot; height=&quot;300&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This screenshot is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;M&apos;&lt;/code&gt; reconstructed with only 32 (out of 1024) components.  &lt;em&gt;Right click + Open in new tab&lt;/em&gt; for 1:1 quality.&lt;/p&gt;

&lt;p&gt;Below is a video with the same image pair as more and more components are used for reconstruction. Most of the action happens in the first few frames.&lt;/p&gt;

&lt;video controls=&quot;controls&quot; playsinline=&quot;playsinline&quot; loop=&quot;&quot; src=&quot;/uploads/2023/chemaguerra-moon-1024.mp4&quot; width=&quot;600&quot; height=&quot;300&quot; poster=&quot;/uploads/2023/chemaguerra-moon-poster.png&quot; alt=&quot;&quot; /&gt;
&lt;p&gt;” preload=”none”&amp;gt;&amp;lt;/video&amp;gt;&lt;/p&gt;

&lt;p&gt;YouTube version: https://youtu.be/6kzaotZlEWo&lt;/p&gt;

&lt;p&gt;What’s remarkable here (the magic of PCA/SVD) is how quickly the error graph decreases. This proves that the first components capture most of the information present in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;M&lt;/code&gt;, while the trailing components only carry high-frequency/low-amplitude fine details.&lt;/p&gt;

&lt;p&gt;This is reminiscent of what happens with the Fourier Transform, the Cosine/Sine Transform and such. Those transforms deal with the space vs. frequency duality, whereas PCA/SVD is purely a variance-driven change-of-basis. But in a similar fashion, all these methods transform information to a dual form where the “amount of information” emerges in a structured, manageable way.&lt;/p&gt;

&lt;p&gt;The FT/CT/etc… lie at the foundation of &lt;em&gt;.jpeg&lt;/em&gt;, &lt;em&gt;.mp3&lt;/em&gt; and other compression systems which exploit the fact that the Human Perception System is more sensitive to luminance (vs. chromaticity), and to lower (vs. higher) frequencies.&lt;/p&gt;

&lt;p&gt;In the case of SVD/PCA, the upper coefficients in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Σ&lt;/code&gt; capture more data variance than the lower ones.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/uploads/2023/chemaguerra-moon-sequence.png&quot; width=&quot;600&quot; height=&quot;200&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;These sequences are reconstructions with 2, 4, 8, 16, 32, 64, and 128 coefficients.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/uploads/2023/chemaguerra-boi-sequence.png&quot; width=&quot;600&quot; height=&quot;200&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;video controls=&quot;controls&quot; playsinline=&quot;playsinline&quot; loop=&quot;&quot; src=&quot;/uploads/2023/chemaguerra-boi-1024.mp4&quot; width=&quot;600&quot; height=&quot;300&quot; poster=&quot;/uploads/2023/chemaguerra-boi-poster.png&quot; alt=&quot;&quot; /&gt;
&lt;p&gt;” preload=”none”&amp;gt;&amp;lt;/video&amp;gt;&lt;/p&gt;

&lt;p&gt;YouTube version: https://youtu.be/dOujW5C-A2A&lt;/p&gt;

&lt;h3 id=&quot;easier-vs-harder-cases&quot;&gt;Easier vs. harder cases&lt;/h3&gt;

&lt;p&gt;As explained above, the matrix factorization can be interpreted as a change of basis to a special space where the data has rows which are linearly dependent with each other. In such case, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;U/V&lt;/code&gt; matrices of a lower rank will suffice to reconstruct the original matrix exactly. Actually, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Σ&lt;/code&gt; will present itself with as many zero-valued coefficients in its diagonal as rows/columns can be trashed without causing any loss of data.&lt;/p&gt;

&lt;p&gt;An extreme case is presented below (a centered square box shape), where 1 coefficient/row/col suffices. In this case both inside and outside the shape, all rows/cols are identical. A box is a separable convolution filter, BTW (future post on low-rank convolution incoming, I hope).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/uploads/2023/chemaguerra-rect-sequence.png&quot; width=&quot;600&quot; height=&quot;200&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Rotating the shape brings disaster despite PCA/SVD are capable of “auto-detecting” such changes of basis. But here we’re dealing with discrete math, so the rotated shape gets “pixelated” and this makes the decomposition become numerically impure.&lt;/p&gt;

&lt;p&gt;It’s funny to see how in the first frames of the video the reconstruction “insists” on being an unrotated square, somehow.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/uploads/2023/chemaguerra-tilt-sequence.png&quot; width=&quot;600&quot; height=&quot;200&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;video controls=&quot;controls&quot; playsinline=&quot;playsinline&quot; loop=&quot;&quot; src=&quot;/uploads/2023/chemaguerra-tilt-256.mp4&quot; width=&quot;600&quot; height=&quot;300&quot; poster=&quot;/uploads/2023/chemaguerra-tilt-poster.png&quot; alt=&quot;&quot; /&gt;
&lt;p&gt;” preload=”none”&amp;gt;&amp;lt;/video&amp;gt;&lt;/p&gt;

&lt;p&gt;Below, a pentagonal shape.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/uploads/2023/chemaguerra-penta-sequence.png&quot; width=&quot;600&quot; height=&quot;200&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;video controls=&quot;controls&quot; playsinline=&quot;playsinline&quot; loop=&quot;&quot; src=&quot;/uploads/2023/chemaguerra-penta-256.mp4&quot; width=&quot;600&quot; height=&quot;300&quot; poster=&quot;/uploads/2023/chemaguerra-penta-poster.png&quot; alt=&quot;&quot; /&gt;
&lt;p&gt;” preload=”none”&amp;gt;&amp;lt;/video&amp;gt;&lt;/p&gt;

&lt;h3 id=&quot;practical-uses&quot;&gt;Practical uses&lt;/h3&gt;

&lt;p&gt;There are interesting practical uses for SVD truncation other than dimensionality reduction in data analysis.&lt;/p&gt;

&lt;h4 id=&quot;data-compression&quot;&gt;Data compression&lt;/h4&gt;

&lt;p&gt;&lt;a href=&quot;https://bartwronski.com/2020/05/21/dimensionality-reduction-for-image-and-texture-set-compression/&quot;&gt;Bart Wronski&lt;/a&gt; has a very interesting write up on &lt;em&gt;compression of PBR texture sets&lt;/em&gt; using this technique.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;BCn Texture Compression&lt;/em&gt; is based on dimensionality reduction as well. Nice write up on the subject by &lt;a href=&quot;https://www.reedbeta.com/blog/understanding-bcn-texture-compression-formats/&quot;&gt;Nathan Reed&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&quot;low-rank-approximation&quot;&gt;Low-rank approximation&lt;/h4&gt;

&lt;p&gt;(Low-rank approximation)[https://en.wikipedia.org/wiki/Low-rank_approximation].&lt;/p&gt;

&lt;p&gt;Another interesting read by &lt;a href=&quot;https://bartwronski.com/2020/02/03/separate-your-filters-svd-and-low-rank-approximation-of-image-filters/&quot;&gt;Bart Wronski&lt;/a&gt;. I wish to do my own write up on &lt;em&gt;low-rank convolution&lt;/em&gt; soon.&lt;/p&gt;

&lt;h3 id=&quot;implementation-details&quot;&gt;Implementation details&lt;/h3&gt;

&lt;p&gt;I had some old PCA/SVD C++ code in &lt;a href=&quot;https://maverickrender.com/&quot;&gt;Maverick&lt;/a&gt;’s API, which I used for the images/videos in this post. But after reading this post by &lt;a href=&quot;https://blog.demofox.org/2022/07/12/calculating-svd-and-pca-in-c/&quot;&gt;Atrix256&lt;/a&gt; I may bite the bullet and replace the implementation part of my old &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;xsvd_c&lt;/code&gt; class with &lt;a href=&quot;https://eigen.tuxfamily.org/&quot;&gt;Eigen&lt;/a&gt;.&lt;/p&gt;</content><author><name></name></author><category term="math" /><category term="2d" /><category term="coding" /><summary type="html">NOTE: This write-up is not finished yet…</summary></entry><entry><title type="html">Reprojection Temporal Anti-Aliasing</title><link href="http://localhost:4000/render/math/3d/coding/2023/05/06/reprojection-temporal-antialiasing.html" rel="alternate" type="text/html" title="Reprojection Temporal Anti-Aliasing" /><published>2023-05-06T19:46:49+02:00</published><updated>2023-05-06T19:46:49+02:00</updated><id>http://localhost:4000/render/math/3d/coding/2023/05/06/reprojection-temporal-antialiasing</id><content type="html" xml:base="http://localhost:4000/render/math/3d/coding/2023/05/06/reprojection-temporal-antialiasing.html">&lt;p&gt;Recently I dived into the rabbit-hole of real-time anti-aliasing techniques and ended up implementing &lt;strong&gt;Reprojection-based Temporal Anti-Aliasing&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Here’s my TAA prototype, in Shadertoy form:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.shadertoy.com/view/ct33WB&quot;&gt;Shadertoy: Reprojection Temporal AA&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I am not embedding the shadertoy here to avoid web browser crashes. So here’s a recording instead:&lt;/p&gt;

&lt;video controls=&quot;controls&quot; playsinline=&quot;playsinline&quot; loop=&quot;&quot; src=&quot;/uploads/2023/e58238cef1.mp4&quot; width=&quot;600&quot; height=&quot;337&quot; poster=&quot;/uploads/2023/7324e24ba3.png&quot; alt=&quot;&quot; /&gt;
&lt;p&gt;” preload=”none”&amp;gt;&amp;lt;/video&amp;gt;&lt;/p&gt;

&lt;p&gt;From &lt;a href=&quot;https://en.wikipedia.org/wiki/Temporal_anti-aliasing&quot;&gt;Wikipedia&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;“Temporal anti-aliasing (TAA) … combines information from past frames and the current frame to remove jaggies in the current frame. In TAA, each pixel is sampled once per frame but in each frame the sample is at a different location within the image. Pixels sampled in past frames are blended with pixels sampled in the current frame to produce an anti-aliased image.”&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;I won’t get super-deep into the details here. Please take a look at my shadertoy implementation instead. But before that, feel free to enjoy these seminal TAA resources:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=2XXS5UyNjjU&quot;&gt;GDC/playdead/INSIDE/Lasse&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://advances.realtimerendering.com/s2014/#_HIGH-QUALITY_TEMPORAL_SUPERSAMPLING&quot;&gt;UE4/Karis&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/uploads/2023/f0b985bae1.png&quot; width=&quot;600&quot; height=&quot;600&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;the-intuition-behind-temporal-aa&quot;&gt;The intuition behind &lt;em&gt;Temporal&lt;/em&gt; AA&lt;/h3&gt;

&lt;p&gt;Most AA solutions sample each frame pixel multiple times (randomizing the sampling, jittering the camera, etc…) and output the averaged samples to the display. A straightforward example of this is MSAA, where each rasterized pixel is exploded into &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;N&lt;/code&gt; fragments that get scattered through the surface of the pixel. The eventual output is simply the average of those fragments.&lt;/p&gt;

&lt;p&gt;This means that each frame will take (potentially) &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;N&lt;/code&gt; times longer to compute if AA is enabled.&lt;/p&gt;

&lt;p&gt;On the other hand, Temporal AA samples each frame pixel -only once- and then averages the information found in the past &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;N&lt;/code&gt; frames to complete the current frame. This is achieved by &lt;em&gt;rewinding the current pixel back in time into the previous frame(s)&lt;/em&gt; via perspective/motion reprojection.&lt;/p&gt;

&lt;p&gt;This sounds like the holy grail of AA, because we can’t expect to go lower than one sample per pixel. TAA is indeed remarkably fast, and delivers quality comparable to other classic AA solutions. As a matter of fact, TAA has become the de-facto standard in game engines, and is even the foundation of higher-order algorithms such as DLSS.&lt;/p&gt;

&lt;p&gt;However, implementation is tricky and finicky, and some requirements must be met by your engine before support for TAA can be added.&lt;/p&gt;

&lt;h3 id=&quot;reprojection-into-the-previous-frame&quot;&gt;Reprojection (into the previous frame)&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Reprojection&lt;/em&gt; means figuring out the location of a current frame pixel in the previous frame:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Do nothing if everything is completely static (trivial case).&lt;/li&gt;
  &lt;li&gt;If 1px shear jittering is used: Undo jittering from the current frame and do jittering in the previous frame. This will reconstruct proper AA in all contours pretty much like MSAA would.&lt;/li&gt;
  &lt;li&gt;If the camera is moving: Unproject the pixel to world space with the current frame’s camera projection and then reproject from world space with the previous frame’s camera projection.&lt;/li&gt;
  &lt;li&gt;If the objects are moving: Unproject the pixel, then subtract the motion vector corresponding to the object the pixel belongs to, and reproject with the previous frame’s camera projection.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In the general case, all the above combined are needed.&lt;/p&gt;

&lt;h3 id=&quot;blending-with-the-history-buffer&quot;&gt;Blending with the history buffer&lt;/h3&gt;

&lt;p&gt;For TAA we will just make the output of the current frame become the history frame for the next frame.&lt;/p&gt;

&lt;p&gt;For the blending policy between current vs. history (reprojected) pixels we may use an &lt;em&gt;Exponential Moving Average&lt;/em&gt;. As the weight used for blending &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;current&apos;:=lerp(weight,current,history)&lt;/code&gt; becomes lower and lower, the EMA converges to an arithmetic average of the past (infinite) frames.&lt;/p&gt;

&lt;p&gt;This means &lt;em&gt;infinite storage in finite space&lt;/em&gt;. Kind of…&lt;/p&gt;

&lt;p&gt;Note that this continuous blending of pixel colors may cause some degree of &lt;em&gt;smearing and ghosting&lt;/em&gt; in the frame. Especially when objects become occluded/unoccluded, pop in/out of the frame, or when the camera is shaking vigorously.&lt;/p&gt;

&lt;h3 id=&quot;reprojection-is-inherently-faulty&quot;&gt;Reprojection is inherently faulty&lt;/h3&gt;

&lt;p&gt;Unfortunately, when a pixel is reprojected back in time the information we’re looking for may simply not be there. &lt;em&gt;i.e.,&lt;/em&gt; the current pixel was occluded (or out of the screen) in the previous frame.&lt;/p&gt;

&lt;p&gt;Such situations can’t be avoided. So we need some policy to decide to what extent a reprojected pixel must be accepted or rejected.&lt;/p&gt;

&lt;p&gt;Some reasonable possibilities are: keeping track of object/material IDs per pixel, keeping track of abrupt changes in the pixel’s depth, etc… However besides the extra buffer readouts, these ideas prove to be generally ad-hoc and unreliable.&lt;/p&gt;

&lt;p&gt;A much simpler idea is to blend proportionally to the difference in color (or luminance). Which is simple enough and &lt;em&gt;kind of works&lt;/em&gt;, but produces tons of motion smearing… until it is combined with &lt;em&gt;color clipping&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;I believe that Sousa/Lottas/Karis (?) came up with a genius idea that is very stable, but also efficient and easy to implement without any extra pre-requisites:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;clip the reprojected pixel color to the min-max color of the pixel’s neighborhood in the current frame&lt;/em&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The rationale here is that eventually (&lt;em&gt;e.g.,&lt;/em&gt; when the camera stabilizies) each anti-aliased pixel will converge to a color that is a function of itself and its neighbors. So clipping the reprojected pixel in the history buffer to said min-max range ensures that highly different colors (&lt;em&gt;i.e.,&lt;/em&gt; good candidates for rejection) won’t pull too hard from the current blend, while acceptable values (already within range) will blend peacefully.&lt;/p&gt;

&lt;p&gt;This works surprisingly well and, if implemented carefully, keeps flicker/smearing/ghosting to a minimum.&lt;/p&gt;

&lt;h3 id=&quot;pre-requisites&quot;&gt;Pre-requisites&lt;/h3&gt;

&lt;p&gt;All the above require from your engine:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;WxH&lt;/code&gt; history buffer. 1 color per pixel.&lt;/li&gt;
  &lt;li&gt;If objects are moving: A velocity buffer with 1 motion vector per pixel.&lt;/li&gt;
  &lt;li&gt;Recalling the camera projection and jittering used in the previous frame.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Then, TAA becomes a one-pass full-frame pixel shader that reprojects/clips/weighs pixels as described.&lt;/p&gt;

&lt;h3 id=&quot;bonuses&quot;&gt;Bonuses&lt;/h3&gt;

&lt;p&gt;Since TAA averages pixel colors over time while being agnostic to how those colors came up to be, it &lt;em&gt;auto-magically&lt;/em&gt; helps converge &lt;em&gt;every&lt;/em&gt; effect that samples over time in the frame. &lt;em&gt;i.e.,&lt;/em&gt; stochastic effects such as AO, volumetrics, etc…&lt;/p&gt;

&lt;p&gt;So it kind of doubles as Temporal AA and Temporal denoising. :-)&lt;/p&gt;</content><author><name></name></author><category term="render" /><category term="math" /><category term="3d" /><category term="coding" /><summary type="html">Recently I dived into the rabbit-hole of real-time anti-aliasing techniques and ended up implementing Reprojection-based Temporal Anti-Aliasing.</summary></entry><entry><title type="html">Tiny path tracing in 2D</title><link href="http://localhost:4000/render/2d/physics/coding/2023/04/14/tiny-path-tracing.html" rel="alternate" type="text/html" title="Tiny path tracing in 2D" /><published>2023-04-14T05:46:42+02:00</published><updated>2023-04-14T05:46:42+02:00</updated><id>http://localhost:4000/render/2d/physics/coding/2023/04/14/tiny-path-tracing</id><content type="html" xml:base="http://localhost:4000/render/2d/physics/coding/2023/04/14/tiny-path-tracing.html">&lt;p&gt;This is a tiny pixelshader-only 2D path tracing engine. In my (little) spare time I’ve been writing a small C++ videogame/real-time engine and am doing some little experiments from time to time.&lt;/p&gt;

&lt;p&gt;The fragment shader here does stochastic PT and NEE, and MIS to weigh both. The rays and scene obstacles are all in 2D (line segments and rectangles).&lt;/p&gt;

&lt;p&gt;The 2 moving cubes are controlled by a gamepad, and the third cube that shows up in the trajectory between one and the other is a collision-detection test using the classic AABB vs. swept AABB algorithm (&lt;a href=&quot;https://en.wikipedia.org/wiki/Minkowski_addition&quot;&gt;minkowski sum&lt;/a&gt;, etc…).&lt;/p&gt;

&lt;video controls=&quot;controls&quot; playsinline=&quot;playsinline&quot; loop=&quot;&quot; src=&quot;/uploads/2023/5600e78e35.mp4&quot; width=&quot;600&quot; height=&quot;600&quot; poster=&quot;/uploads/2023/7147e9fccb.png&quot; alt=&quot;&quot; /&gt;
&lt;p&gt;” preload=”none”&amp;gt;&amp;lt;/video&amp;gt;&lt;/p&gt;

&lt;p&gt;Posted on my Twitter account for personal projects:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://twitter.com/topotoygames/status/1646473620447809538&quot;&gt;twitter.com/topotoyga…&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><category term="render" /><category term="2d" /><category term="physics" /><category term="coding" /><summary type="html">This is a tiny pixelshader-only 2D path tracing engine. In my (little) spare time I’ve been writing a small C++ videogame/real-time engine and am doing some little experiments from time to time.</summary></entry><entry><title type="html">Wool flyaways</title><link href="http://localhost:4000/render/math/3d/physics/coding/2023/01/07/wool-flyaways.html" rel="alternate" type="text/html" title="Wool flyaways" /><published>2023-01-07T07:40:37+01:00</published><updated>2023-01-07T07:40:37+01:00</updated><id>http://localhost:4000/render/math/3d/physics/coding/2023/01/07/wool-flyaways</id><content type="html" xml:base="http://localhost:4000/render/math/3d/physics/coding/2023/01/07/wool-flyaways.html">&lt;p&gt;Searching for a proper formulation for flyaways in wool and fabric in general.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/uploads/2023/064e11496c.png&quot; width=&quot;600&quot; height=&quot;850&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;These are some simulations of growth from the root being randomly affected. From top to bottom, using different seeds. From left to right, the resulting B-Spline being evaluated using few or many control points.&lt;/p&gt;

&lt;p&gt;Everything happens in 3D, but this image is just the X-Z projection.&lt;/p&gt;

&lt;h3 id=&quot;force-field-dynamics&quot;&gt;Force-field dynamics&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;e.g.,&lt;/em&gt; wind, vibrations, etc…&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/uploads/2023/9e4ac4452a.gif&quot; width=&quot;256&quot; height=&quot;256&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/uploads/2023/f8cee9565f.gif&quot; width=&quot;256&quot; height=&quot;256&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;</content><author><name></name></author><category term="render" /><category term="math" /><category term="3d" /><category term="physics" /><category term="coding" /><summary type="html">Searching for a proper formulation for flyaways in wool and fabric in general.</summary></entry><entry><title type="html">u32 to f32 in [0..1)</title><link href="http://localhost:4000/math/coding/2023/01/07/u-to-f.html" rel="alternate" type="text/html" title="u32 to f32 in [0..1)" /><published>2023-01-07T00:30:14+01:00</published><updated>2023-01-07T00:30:14+01:00</updated><id>http://localhost:4000/math/coding/2023/01/07/u-to-f</id><content type="html" xml:base="http://localhost:4000/math/coding/2023/01/07/u-to-f.html">&lt;p&gt;Many sampling algorithms take as input random numbers in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[0..1)&lt;/code&gt; interval. On the other hand, Pseudo-Random Number Generators usually produce their output as (unsigned) integer 32-bit or 64-bit numbers.&lt;/p&gt;

&lt;p&gt;It is trivial to turn an &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;u:u32&lt;/code&gt; integer into an &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;f:[0..1]&lt;/code&gt; floating-point value, dividing &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;u&lt;/code&gt; by &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;2^32-1&lt;/code&gt;. This is because &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;u&lt;/code&gt; ranges in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[0..2^32-1]&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;One might think that &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;u/2^32&lt;/code&gt; would produce a floating-point value lower than 1. But it does &lt;em&gt;not&lt;/em&gt;, as evidenced by this loop:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/uploads/2023/d9f7f64c4a.png&quot; width=&quot;600&quot; height=&quot;261&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The number printed out happens to be &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;0x100000101&lt;/code&gt; which is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;2^32+257&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;( u / static_cast&amp;lt; f32_t &amp;gt;( 0x100000101ull ) )&lt;/code&gt; is the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;f:[0..1)&lt;/code&gt; we were looking for.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;( u / static_cast&amp;lt; f64_t &amp;gt;( 0x100000080ull ) )&lt;/code&gt; does the same in double-precision.&lt;/p&gt;</content><author><name></name></author><category term="math" /><category term="coding" /><summary type="html">Many sampling algorithms take as input random numbers in the [0..1) interval. On the other hand, Pseudo-Random Number Generators usually produce their output as (unsigned) integer 32-bit or 64-bit numbers.</summary></entry><entry><title type="html">Micro-Patch Displacement Mapping</title><link href="http://localhost:4000/3d/coding/math/render/2022/09/30/micropatch-displacement-mapping.html" rel="alternate" type="text/html" title="Micro-Patch Displacement Mapping" /><published>2022-09-30T23:01:34+02:00</published><updated>2022-09-30T23:01:34+02:00</updated><id>http://localhost:4000/3d/coding/math/render/2022/09/30/micropatch-displacement-mapping</id><content type="html" xml:base="http://localhost:4000/3d/coding/math/render/2022/09/30/micropatch-displacement-mapping.html">&lt;p&gt;One major endeavour that I undertook this past summer was the creation of a novel displacement mapping system for &lt;a href=&quot;https://maverickrender.com/&quot;&gt;Maverick Render&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The main motivations behind this have been:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Our customers were running out of GPU memory too often when using displacement.&lt;/li&gt;
  &lt;li&gt;Our main goal is that &lt;strong&gt;Maverick is an exquisite-quality tool for model visualization&lt;/strong&gt;. Hence displacement is very important to us.&lt;/li&gt;
  &lt;li&gt;Open the door to some other geometry-generation features beyond displacement itself.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So I undusted the old &lt;em&gt;virtualized geometry&lt;/em&gt; solution I implemented for &lt;a href=&quot;https://randomcontrol.com&quot;&gt;fryrender&lt;/a&gt; back in 2008 and re-engineered it for the Maverick core in the GPU.&lt;/p&gt;

&lt;h3 id=&quot;say-hi-to-micro-patch-displacement-mapping&quot;&gt;Say hi to: Micro-Patch Displacement Mapping&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Non-affine MPDM in arbitrarily-curved surfaces&lt;/em&gt;&lt;/p&gt;

&lt;!-- &lt;video controls=&quot;controls&quot; playsinline=&quot;playsinline&quot; loop src=&quot;/uploads/2022/ffa546d832.mp4&quot; width=&quot;600&quot; height=&quot;600&quot; poster=&quot;/uploads/2022/0c42143df2.png&quot; alt=&quot;&quot; /&gt;&quot; preload=&quot;none&quot;&gt;&lt;/video&gt; --&gt;

&lt;p&gt;&lt;em&gt;Affine MPDM in flat surfaces&lt;/em&gt;&lt;/p&gt;

&lt;!-- &lt;video controls=&quot;controls&quot; playsinline=&quot;playsinline&quot; loop src=&quot;/uploads/2022/96178f84c6.mp4&quot; width=&quot;600&quot; height=&quot;600&quot; poster=&quot;/uploads/2022/7016a7ae6d.png&quot; alt=&quot;&quot; /&gt;&quot; preload=&quot;none&quot;&gt;&lt;/video&gt; --&gt;

&lt;p&gt;Some good properties of Maverick’s displacement:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;No requirements &lt;em&gt;whatsoever&lt;/em&gt; on the base mesh or on the heightmap texture.&lt;/li&gt;
  &lt;li&gt;It costs near 0 in warm-up time.&lt;/li&gt;
  &lt;li&gt;It costs near 0 in memory (only a small payload is appended to the height map).&lt;/li&gt;
  &lt;li&gt;0 information is lost; every single texel in the heightmap is turned into a displaced &lt;em&gt;micro-patch&lt;/em&gt;.&lt;/li&gt;
  &lt;li&gt;Implemented as a custom primitive in Maverick’s OptiX ray-tracing backend.&lt;/li&gt;
  &lt;li&gt;Used every trick in the book to optimize it as much as I could.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;mpdm-vs-brute-force&quot;&gt;MPDM vs. brute-force&lt;/h3&gt;

&lt;p&gt;MPDM is meant to address some classic problems with the &lt;em&gt;subdivide-and-displace-vertices&lt;/em&gt; (brute-force) approach. Using brute-force:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;There is some (often significant) wait time for warm-up.&lt;/li&gt;
  &lt;li&gt;Memory usage goes through the roof, more than often blowing up all available memory.&lt;/li&gt;
  &lt;li&gt;Height sampling happens at the vertices and not at the heightmap texels.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Points 1-2 are very obvious. It becomes impossible to abuse displacement, or to recklessly use it for large surfaces. Some techniques such as back-face culling or camera culling can be used to work around these difficulties, but such techniques pose problems on their own. Expecting the user to be careful not to exceed his memory budget is always an ill-fated plan.&lt;/p&gt;

&lt;p&gt;Point 3 often means that the resulting displacement is smudgy, and not as crisp as it should be. &lt;em&gt;i.e.,&lt;/em&gt; information is lost, and/or geometry is produced in excess. Some techniques (that Maverick itself has featured in the past) such as &lt;em&gt;autobump&lt;/em&gt; can be used to work around this problem by kind-of-restoring the information that is lost in the process. But then again, optimal configuration would become the responsibility of the user.&lt;/p&gt;

&lt;p&gt;None of these issues happen with MPDM. :-)&lt;/p&gt;

&lt;h3 id=&quot;are-there-any-benefits-to-the-old-brute-force-approach&quot;&gt;Are there any benefits to the old brute-force approach?&lt;/h3&gt;

&lt;p&gt;As usual, nothing really good comes without a price. This is often very true in the realm of algorithm optimization.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;MPDM unfolds virtualized geometry during ray-traversal. The displaced geometry &lt;em&gt;never&lt;/em&gt; exists for real in memory (that is why it is said to be &lt;em&gt;virtualized&lt;/em&gt;) and this is the reason why MPDM has a near 0-cost in memory usage. However, this virtualization comes at an algorithmic cost. Despite massively optimized, MPDM renders a bit more slowly than the same displaced geometry would if the vertices were pre-displaced during warm-up and entered the ray-tracing BVH as regular geometry.&lt;/li&gt;
  &lt;li&gt;For MPDM, part of the optimization process relies on the fact that the input map is discretized in &lt;em&gt;texels&lt;/em&gt;, (as in a regular bitmap). For brute-force displacement the only requirement is that the height map can be evaluated at each geometry vertex, which is true to bitmaps, procedurals, and all map types. So MPDM is a priori limited to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;filetex&lt;/code&gt; maps, but we have added to Maverick a new map type called &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bakemap&lt;/code&gt; so the user can bake any procedural map tree into a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;filetex&lt;/code&gt; to feed MPDM if necessary.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;how-does-mpdm-work&quot;&gt;How does MPDM work?&lt;/h3&gt;

&lt;p&gt;Here’s a very broad explanation on how MPDM in Maverick works:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A (rather classic) hierarchical partitioning scheme based in min-max mip-map levels is performed on the input heightmap. As depicted in the images below.&lt;/li&gt;
  &lt;li&gt;Those voxels are efficiently ray-traceable… unless there is curvature in the base mesh. Hell breaks loose as soon as curvature is at play. Maverick does non-affine math here (visualized in a previous post on non-affine &lt;a href=&quot;https://www.brashandplucky.com/2022/07/07/barycentric-coords-in.html&quot;&gt;triangle sweeps&lt;/a&gt;). I’ve tried different approaches for this (non-affine, discretized, and hybrid), and the code allows to flag-switch each mode on and off.&lt;/li&gt;
  &lt;li&gt;Because of the non-affine treatment, at the lowest hierarchy level you no longer have quads or triangles, but bilinear patches (hence the name: &lt;em&gt;Micro-PATCH Displacement Mapping&lt;/em&gt;).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;Non-affine MPDM in arbitrarily-curved surfaces&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/uploads/2022/58b6c6fb54.png&quot; width=&quot;600&quot; height=&quot;400&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;The input heightmap used&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/uploads/2022/175b195678.jpg&quot; width=&quot;512&quot; height=&quot;512&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Affine MPDM in flat surfaces (special optimization branch)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/uploads/2022/a1ab151eee.png&quot; width=&quot;600&quot; height=&quot;400&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;The input heightmap used&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/uploads/2022/98cf72db76.jpg&quot; width=&quot;512&quot; height=&quot;512&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;But the devil lies in the details. Efficient implementation of this all was a multi-week hell working with data structures, low-level optimizations, coordinating MPDM with OptiX and the rest of the Maverick core, and dealing with plenty of non-obvious fine-grain issues such as:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Avoiding cracks across edges.&lt;/li&gt;
  &lt;li&gt;Dealing with UV mapping projections.&lt;/li&gt;
  &lt;li&gt;Transfer of shading normals.&lt;/li&gt;
  &lt;li&gt;Real-time notifications from the UI.&lt;/li&gt;
  &lt;li&gt;…&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Youtube 4K videos:&lt;/p&gt;

&lt;iframe width=&quot;640&quot; height=&quot;640&quot; src=&quot;http://www.youtube.com/embed/2PdRx0sALgg?color=white&amp;amp;theme=light&quot;&gt;&lt;/iframe&gt;
&lt;iframe width=&quot;640&quot; height=&quot;640&quot; src=&quot;http://www.youtube.com/embed/O9qUCZTxkTQ?color=white&amp;amp;theme=light&quot;&gt;&lt;/iframe&gt;
&lt;iframe width=&quot;640&quot; height=&quot;640&quot; src=&quot;http://www.youtube.com/embed/ZKcLPQkhFWc?color=white&amp;amp;theme=light&quot;&gt;&lt;/iframe&gt;
&lt;iframe width=&quot;640&quot; height=&quot;640&quot; src=&quot;http://www.youtube.com/embed/Y9DFtEo5Hgo?color=white&amp;amp;theme=light&quot;&gt;&lt;/iframe&gt;</content><author><name></name></author><category term="3d" /><category term="coding" /><category term="math" /><category term="render" /><summary type="html">One major endeavour that I undertook this past summer was the creation of a novel displacement mapping system for Maverick Render.</summary></entry><entry><title type="html">Diffraction vs. Multi-resolution</title><link href="http://localhost:4000/render/math/3d/2d/physics/coding/2022/09/29/diffraction-vs-multiresolution.html" rel="alternate" type="text/html" title="Diffraction vs. Multi-resolution" /><published>2022-09-29T14:25:49+02:00</published><updated>2022-09-29T14:25:49+02:00</updated><id>http://localhost:4000/render/math/3d/2d/physics/coding/2022/09/29/diffraction-vs-multiresolution</id><content type="html" xml:base="http://localhost:4000/render/math/3d/2d/physics/coding/2022/09/29/diffraction-vs-multiresolution.html">&lt;p&gt;I’ve been working lately on glare/bloom/fringe and other post-processing effects in &lt;a href=&quot;https://maverickrender.com&quot;&gt;Maverick Render&lt;/a&gt;. Some of these inherit from our lovely &lt;a href=&quot;https://arionfx.com&quot;&gt;ArionFX&lt;/a&gt; Adobe Photoshop and AfterEffects plug-in.&lt;/p&gt;

&lt;p&gt;One complaint in ArionFX and also in Maverick is (was, because this post is about a successful fix) that Glare/Bloom diverge in &lt;em&gt;shape and power&lt;/em&gt; when the input image is rendered at a different resolution, even if the Glare/Bloom parameters stay the same.&lt;/p&gt;

&lt;p&gt;There are some relatively unobvious reasons for this. Basically, the challenges are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;Hard challenge&lt;/em&gt;: Diffraction is a frequency analysis effect. For a render, this happens in the discrete realm (pixels). The size (amount of pixels) of the images involved changes what frequencies and how they show up in the Fourier Transform.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Hard challenge&lt;/em&gt;: Anti-Aliasing of neighboring pixels (more prevalent at low resolution) averages their power and dims the overall Glare/Bloom overlay. This can pose a real problem for thin geometries such as lightbulb filaments.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Easy challenge&lt;/em&gt;: As illustrated in some of my previous posts, the FT itself has some properties that relate its scale and power to the scale and power of the aperture/obstacle of the lens iris. These of course must be compensated for.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Medium challenge&lt;/em&gt;: Changes in aspect ratio, or in padding in the image buffers (such as the padding between the IPR size in the UI vs. the canvas size) must be taken into account as well.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The upcoming release of Maverick will address these issues.&lt;/p&gt;

&lt;p&gt;Here’s a small video with a sequence of Maverick post-processing effects, all rendered alternating landscape and portrait aspect ratios between 512 and 2048. The video is cropped as landscape to be easier on the eyes. As can be seen, at lower resolutions there’s always some power divergence, and a little bit of blur. But those are unavoidable to some extent.&lt;/p&gt;

&lt;video controls=&quot;controls&quot; playsinline=&quot;playsinline&quot; loop=&quot;&quot; src=&quot;/uploads/2022/b074dc2188.mp4&quot; width=&quot;1024&quot; height=&quot;512&quot; poster=&quot;/uploads/2022/f660e33ea4.png&quot; preload=&quot;none&quot;&gt;&lt;/video&gt;

&lt;p&gt;Youtube 4K version: &lt;a href=&quot;https://youtu.be/4K8F8vP76Y0&quot;&gt;youtu.be/4K8F8vP76…&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><category term="render" /><category term="math" /><category term="3d" /><category term="2d" /><category term="physics" /><category term="coding" /><summary type="html">I’ve been working lately on glare/bloom/fringe and other post-processing effects in Maverick Render. Some of these inherit from our lovely ArionFX Adobe Photoshop and AfterEffects plug-in.</summary></entry><entry><title type="html">Flyby heatmaps (i)</title><link href="http://localhost:4000/render/3d/coding/2022/09/22/flyby-heatmaps-i.html" rel="alternate" type="text/html" title="Flyby heatmaps (i)" /><published>2022-09-22T06:46:29+02:00</published><updated>2022-09-22T06:46:29+02:00</updated><id>http://localhost:4000/render/3d/coding/2022/09/22/flyby-heatmaps-i</id><content type="html" xml:base="http://localhost:4000/render/3d/coding/2022/09/22/flyby-heatmaps-i.html">&lt;p&gt;These are some technical visualizations from the all-new 0-memory geometry generation subsystem in &lt;a href=&quot;https://maverickrender.com/&quot;&gt;Maverick Render&lt;/a&gt; which we intend to release soon.&lt;/p&gt;

&lt;p&gt;I will be posting more related images and videos in the upcoming days.&lt;/p&gt;

&lt;video controls=&quot;controls&quot; playsinline=&quot;playsinline&quot; loop=&quot;&quot; src=&quot;/uploads/2022/f063c2bba3.mp4&quot; width=&quot;600&quot; height=&quot;200&quot; poster=&quot;/uploads/2022/2925ae1c46.png&quot; alt=&quot;&quot; /&gt;
&lt;p&gt;” preload=”none”&amp;gt;&amp;lt;/video&amp;gt;&lt;/p&gt;

&lt;video controls=&quot;controls&quot; playsinline=&quot;playsinline&quot; loop=&quot;&quot; src=&quot;/uploads/2022/5c3a9c962b.mp4&quot; width=&quot;600&quot; height=&quot;200&quot; poster=&quot;/uploads/2022/670446493f.png&quot; alt=&quot;&quot; /&gt;
&lt;p&gt;” preload=”none”&amp;gt;&amp;lt;/video&amp;gt;&lt;/p&gt;

&lt;video controls=&quot;controls&quot; playsinline=&quot;playsinline&quot; loop=&quot;&quot; src=&quot;/uploads/2022/5c7290e9b0.mp4&quot; width=&quot;600&quot; height=&quot;200&quot; poster=&quot;/uploads/2022/629aeebe0f.png&quot; alt=&quot;&quot; /&gt;
&lt;p&gt;” preload=”none”&amp;gt;&amp;lt;/video&amp;gt;&lt;/p&gt;

&lt;h3 id=&quot;youtube-versions-of-the-above-videos&quot;&gt;Youtube versions of the above videos&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;[EDIT]&lt;/strong&gt; I believe that micro.blog has some difficulty with (&lt;em&gt;i.e.,&lt;/em&gt; won’t play back) videos encoded at a non-standard aspect ratio. So here are the same videos in Youtube form:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://youtu.be/mORIVYWTrkg&quot;&gt;youtu.be/mORIVYWTr…&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://youtu.be/1VBq42-cF3w&quot;&gt;youtu.be/1VBq42-cF…&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://youtu.be/wOYJUVqYgTo&quot;&gt;youtu.be/wOYJUVqYg…&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;results-in-production&quot;&gt;Results in production&lt;/h3&gt;

&lt;p&gt;The first beneficiary of this subsystem is Displacement Mapping (now Micro-Patch Displacement Mapping &lt;em&gt;a.k.a.,&lt;/em&gt; MPDM). This new MPDM system uses near zero memory, near zero warm-up time, and captures &lt;em&gt;literally and exactly&lt;/em&gt; every single texel in the input texture.&lt;/p&gt;

&lt;video controls=&quot;controls&quot; playsinline=&quot;playsinline&quot; loop=&quot;&quot; src=&quot;/uploads/2022/c5b7dedfa4.mp4&quot; width=&quot;600&quot; height=&quot;200&quot; poster=&quot;/uploads/2022/6a642e65c9.png&quot; alt=&quot;&quot; /&gt;
&lt;p&gt;” preload=”none”&amp;gt;&amp;lt;/video&amp;gt;&lt;/p&gt;

&lt;p&gt;Youtube 4K version: &lt;a href=&quot;https://youtu.be/BfNTDcMCBsE&quot;&gt;youtu.be/BfNTDcMCB…&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><category term="render" /><category term="3d" /><category term="coding" /><summary type="html">These are some technical visualizations from the all-new 0-memory geometry generation subsystem in Maverick Render which we intend to release soon.</summary></entry><entry><title type="html">Glare/Bloom versatility in Maverick</title><link href="http://localhost:4000/render/math/3d/2d/physics/2022/09/16/glarebloom-versatility-in-maverick-render.html" rel="alternate" type="text/html" title="Glare/Bloom versatility in Maverick" /><published>2022-09-16T14:02:00+02:00</published><updated>2022-09-16T14:02:00+02:00</updated><id>http://localhost:4000/render/math/3d/2d/physics/2022/09/16/glarebloom-versatility-in-maverick-render</id><content type="html" xml:base="http://localhost:4000/render/math/3d/2d/physics/2022/09/16/glarebloom-versatility-in-maverick-render.html">&lt;p&gt;These below are a bunch of glare patterns produced with the (much improved) bloom/glare toolchain in &lt;a href=&quot;https://maverickrender.com/&quot;&gt;Maverick Render&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;These tests have been conducted by @Vloba with the soon-to-be-released Maverick Studio 2022.5 and they make use of some of our new procedural maps for aperture.&lt;/p&gt;

&lt;p&gt;These images are expressive of the versatility of the new system.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/uploads/2022/068d29487b.png&quot; width=&quot;600&quot; height=&quot;600&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/uploads/2022/5f0327aaf3.png&quot; width=&quot;600&quot; height=&quot;600&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/uploads/2022/f1d06697ca.png&quot; width=&quot;600&quot; height=&quot;600&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/uploads/2022/2ff7e3d4af.png&quot; width=&quot;600&quot; height=&quot;600&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/uploads/2022/de84a321a8.png&quot; width=&quot;600&quot; height=&quot;600&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/uploads/2022/17dd08f67b.png&quot; width=&quot;600&quot; height=&quot;600&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/uploads/2022/f4bd96616b.png&quot; width=&quot;600&quot; height=&quot;600&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/uploads/2022/ecc2ab6c8d.jpg&quot; width=&quot;600&quot; height=&quot;600&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;</content><author><name></name></author><category term="render" /><category term="math" /><category term="3d" /><category term="2d" /><category term="physics" /><summary type="html">These below are a bunch of glare patterns produced with the (much improved) bloom/glare toolchain in Maverick Render.</summary></entry><entry><title type="html">Bessel functions</title><link href="http://localhost:4000/math/2d/physics/coding/2022/09/06/bessel-functions.html" rel="alternate" type="text/html" title="Bessel functions" /><published>2022-09-06T00:01:04+02:00</published><updated>2022-09-06T00:01:04+02:00</updated><id>http://localhost:4000/math/2d/physics/coding/2022/09/06/bessel-functions</id><content type="html" xml:base="http://localhost:4000/math/2d/physics/coding/2022/09/06/bessel-functions.html">&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Bessel_function&quot;&gt;Bessel functions&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;From Wikipedia&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/uploads/2022/174dfd7548.gif&quot; width=&quot;360&quot; height=&quot;287&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;iterative-implementation&quot;&gt;Iterative implementation&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/uploads/2022/1757d91e71.png&quot; width=&quot;600&quot; height=&quot;266&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I came up with the above implementation, with which I plotted these.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;J0-4 in [0..2pi]&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/uploads/2022/2c2aa59056.png&quot; width=&quot;600&quot; height=&quot;309&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;2*abs(J1-4(x)/x) in [0..2pi]&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/uploads/2022/8d38e482c1.png&quot; width=&quot;600&quot; height=&quot;309&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Iterative methods are a terrible choice for many use cases because of error accumulation, jitter, the very presence of a loop, etc… But in this case this method also happens to be pretty weak and way too easy to break:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;J0-4 in [0..8pi]&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/uploads/2022/701e9aaad8.png&quot; width=&quot;600&quot; height=&quot;309&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;deus-ex-machina&quot;&gt;Deus ex machina&lt;/h3&gt;

&lt;p&gt;After some unsuccessful googling I was about to work on my own &lt;a href=&quot;https://en.wikipedia.org/wiki/Taylor_series&quot;&gt;Taylor Series&lt;/a&gt; approximation or at least study the proposed implementations in &lt;a href=&quot;http://numerical.recipes/webnotes/nr3web8.pdf&quot;&gt;Numerical Recipes&lt;/a&gt;. But I learnt to my surprise :o) that &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;math.h&amp;gt;&lt;/code&gt; provides &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;j0/j1/jn/y0/y1/yn&lt;/code&gt; and even CUDA provides &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;j0f/j1f/jnf/y0f/y1f/ynf&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;I checked whether the C/CUDA implementations match my iterative implementation, and they do.&lt;/p&gt;

&lt;p&gt;For reasons I may discuss in a future post, I am after &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;j1&lt;/code&gt; only, so… &lt;em&gt;my job here is done&lt;/em&gt;.&lt;/p&gt;</content><author><name></name></author><category term="math" /><category term="2d" /><category term="physics" /><category term="coding" /><summary type="html">Bessel functions</summary></entry></feed>